# Development Guide for Pidgin

## What This Project Actually Is

Pidgin is a well-developed research tool with ~20 modules for recording and analyzing AI conversations. We've noticed interesting behaviors but haven't proven anything statistically. The tool is feature-complete for single conversations - what's missing is batch execution and validation.

## Development Environment

### Package Management
This project uses **Poetry** for dependency management:

```bash
# Install poetry
curl -sSL https://install.python-poetry.org | python3 -

# Install dependencies
poetry install

# Add new dependencies
poetry add package-name

# Add dev dependencies
poetry add --group dev package-name

# Run commands in virtual environment
poetry run pidgin chat -a claude -b gpt
```

### Code Style

#### Colors - Nord Theme
Use the Nord color palette for all terminal output:
```python
NORD_COLORS = {
    "nord0": "#2e3440",   # Polar Night - darkest
    "nord1": "#3b4252",   # Polar Night
    "nord2": "#434c5e",   # Polar Night
    "nord3": "#4c566a",   # Polar Night - comments/subtle
    "nord4": "#d8dee9",   # Snow Storm - main content
    "nord5": "#e5e9f0",   # Snow Storm
    "nord6": "#eceff4",   # Snow Storm - brightest
    "nord7": "#8fbcbb",   # Frost - teal
    "nord8": "#88c0d0",   # Frost - light blue
    "nord9": "#81a1c1",   # Frost - blue
    "nord10": "#5e81ac",  # Frost - dark blue
    "nord11": "#bf616a",  # Aurora - red
    "nord12": "#d08770",  # Aurora - orange
    "nord13": "#ebcb8b",  # Aurora - yellow
    "nord14": "#a3be8c",  # Aurora - green
    "nord15": "#b48ead",  # Aurora - purple
}
```

#### Glyphs Not Emoji
Use Unicode glyphs for visual elements:
```python
# Good - geometric glyphs
"â—† Starting conversation"
"â–¶ Continue"
"â–  Stop"
"â—‹ Pending"
"â— Complete"
"âŸ Duration"

# Bad - emoji
"ðŸš€ Starting"
"âœ… Done"
"âŒ Error"
```

Common glyphs:
- Shapes: â—† â—‡ â—‹ â— â–¡ â–  â–² â–¼ â–º â—„
- Arrows: â†’ â† â†” â‡’ â‡ â‡” âžœ 
- Math: â‰ˆ â‰¡ â‰  â‰¤ â‰¥ Â± Ã— Ã·
- Box: â”Œ â” â”” â”˜ â”€ â”‚ â”œ â”¤ â”¬ â”´ â”¼

## Current Reality

### Working âœ…
- Event system records everything
- Streaming from all providers
- Ctrl+C interrupt
- Clean file output

### Partial ðŸš§
- Metrics calculated but not shown
- Context tracking exists but unused

### Missing âŒ
- Batch experiments (critical)
- Statistical analysis
- Message injection
- Pattern validation

## Quick Start

```bash
# Run a conversation
pidgin chat -a claude -b gpt -t 20

# Check output
ls ./pidgin_output/conversations/*/
cat ./pidgin_output/conversations/*/events.jsonl
```

## Architecture That Exists

```
CLI â†’ Conductor â†’ EventBus â†’ events.jsonl
         â†“
     Providers â†’ Streaming â†’ Display
```

Not built: batch runner, analysis tools, validation frameworks.

## Code Guidelines

### What to Build
1. Things that emit events
2. Things that analyze events
3. Things that validate observations

### What NOT to Build
- Complex frameworks
- "Revolutionary" features
- Anything claiming "proven" results

### Adding Features

```python
# Good: Observable action
await self.bus.emit(SomethingHappenedEvent(...))

# Bad: Hidden state
self.secret_state = {"dont": "do this"}
```

## Testing

```bash
pytest                          # Run all tests
pytest tests/test_conductor.py  # Single file
pytest -v --cov=pidgin         # With coverage
```

## Common Tasks

### Run Different Models
```bash
pidgin chat -a opus -b gpt-4.1 -t 30
pidgin chat -a haiku -b gemini -t 50
```

### Check Convergence (manual)
```python
# In the JSON output, look for structural patterns
# No automated tools yet - that's what we need built
```

## Priority Development Areas

### 1. Convergence Threshold System
```python
# Simple threshold-based stopping
if convergence_score >= threshold:
    stop_conversation("high_convergence")
```

Configuration:
```yaml
conversation:
  convergence_threshold: 0.85  # Stop at 85% similarity
  convergence_action: "stop"   # or "warn"
```

### 2. Batch Runner (CRITICAL)
```python
# Concept (not built):
async def run_batch(config, n=100):
    """Run n identical conversations for statistics"""
    results = []
    for i in range(n):
        conv = await run_conversation(config)
        results.append(conv)
    return analyze_patterns(results)
```

### 3. Display Convergence
```python
# Add to display_filter.py
if convergence > 0:
    console.print(f"[{NORD_COLORS['nord3']}]Convergence: {convergence:.2f}[/{NORD_COLORS['nord3']}]")
    if convergence > 0.75:
        console.print(f"[{NORD_COLORS['nord13']}]âš  High convergence warning[/{NORD_COLORS['nord13']}]")
```

## What We've Observed (Not Proven)

- Gratitude spirals in polite models
- Possible linguistic compression
- Model-specific conversation styles
- High sensitivity to initial conditions

These need validation through batch experiments.

## Contributing

We need:
1. **Batch execution** - Run many conversations
2. **Pattern detection** - Find what we're missing  
3. **Statistical tools** - Validate observations
4. **Skeptical review** - Challenge our assumptions

## Don't Do This

- Don't claim discoveries
- Don't add philosophy  
- Don't build frameworks
- Don't compete with MCP

## Do This

- Run experiments
- Analyze data
- Question everything
- Keep it simple

## Research Ethics

- Label everything "preliminary"
- No claims without data
- Open about limitations
- Invite replication

## File Structure
```
pidgin/
â”œâ”€â”€ cli.py              # Command-line interface
â”œâ”€â”€ conductor.py        # Main orchestrator (~500 lines)
â”œâ”€â”€ event_bus.py        # Event publish/subscribe system
â”œâ”€â”€ events.py           # Event type definitions
â”œâ”€â”€ event_logger.py     # Event display formatting
â”œâ”€â”€ display_filter.py   # Human-readable output
â”‚
â”œâ”€â”€ providers/          # AI provider integrations
â”‚   â”œâ”€â”€ anthropic.py    # Claude models
â”‚   â”œâ”€â”€ openai.py       # GPT/O-series
â”‚   â”œâ”€â”€ google.py       # Gemini models
â”‚   â””â”€â”€ xai.py          # Grok models
â”‚
â”œâ”€â”€ dialogue_components/# Separated display components
â”œâ”€â”€ convergence.py      # Convergence calculation
â”‚
â”œâ”€â”€ config.py           # Configuration management
â”œâ”€â”€ context_manager.py  # Token/context tracking
â”œâ”€â”€ convergence.py      # Convergence calculator
â”œâ”€â”€ dimensional_prompts.py # Prompt generation
â”œâ”€â”€ intervention_handler.py # Pause/resume handling
â”œâ”€â”€ metrics.py          # Turn metrics
â”œâ”€â”€ models.py           # Model configurations
â”œâ”€â”€ router.py           # Message routing
â”œâ”€â”€ system_prompts.py   # System prompt templates
â”œâ”€â”€ transcripts.py      # Transcript generation
â”œâ”€â”€ types.py            # Type definitions
â””â”€â”€ user_interaction.py # User interaction

./pidgin_output/        # All output here
â””â”€â”€ conversations/      # Organized by date
```

## Commit Style

```bash
# Lowercase, pragmatic
git commit -m "add batch runner skeleton"
git commit -m "fix convergence display"

# Not
git commit -m "Revolutionize AI Communication"
```

## Remember

1. We built a tool that works
2. We saw interesting patterns
3. We haven't proven anything
4. Statistical validation is the next step

The interesting part isn't what we've built - it's what we might learn from it. But learning requires rigorous experiments we haven't run yet.

Help us find out what's real.